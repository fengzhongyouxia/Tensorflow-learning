迁移学习
参考：
1、https://github.com/dominiek/transferflow
2、https://github.com/kwotsin/transfer_learning_tutorial
3、https://github.com/hzy46/fast-neural-style-tensorflow
4、https://github.com/ghwatson/faststyle


----------
推荐使用： transfer learning for mnist by pb

<font color=#D0000 size=5>理论：</font>
这里将实现从cifar10 迁移到 hymenoptera

从一个模型迁移到另一个，必须保证输入的x（2个模型的输入）形状一致，输出y可以不一致

使用的数据：https://download.pytorch.org/tutorial/hymenoptera_data.zip

神经网络可以从一个任务中学的知识，并将这些知识应用到另一个独立的任务中 
图像识别—迁移到 —-X射线扫描图识别 
如： 你已经训练好一个神经网络，能够识别像猫这样的对应，然后使用那些知识或者部分学得的知识去帮助你更好地阅读X射线扫描图，这就是所谓的迁移学习

假设你已经训练好一个图形识别神经网络，如果你把这个神经网络拿来，适应或者 
说迁移在不同任务中学到的知识，你可以做的是，把神经网络最后的输出层拿走，即删除掉， 
并删除最后一层的权重，然后为最后一层重新赋予随机权重，然后让它在新的数据上训练

要实现迁移学习，把数据集换成新的x，y对（更换训练数据），初始化最后一层的权重，其他层的权重则是提取已经训练好的模型参数 
如果你的新模型数据集很少，你可能只需要重新训练最后一层的权重，并保持其他参数不变， 
如果你的数据足够多，你可以重新训练神经网络中剩下的所有层，

经验规则，如果你有一个小数据集，就只训练输出层前的最后一层，或者最后两层 
如果你有很多数据，那么你可以重新训练网络中的所有参数，如果你重新训练神经网络中的所有参数，那么这个在图像识别数据的初期训练阶段，有时称为预训练，

因为你再用图像识别数据去预先初始化或者预训练神经网络的权重，然后，如果你以后更新所有权重，然后在放射科数据上训练，有时这个过程叫微调

把图像识别中学到的知识应用或迁移到放射科诊断上来，为什么这样有效果？ 
有很多低层次特征，比如说边缘检测，曲线检测，阳性对象检测，从非常大的图像识别数据库中学得的这些能力，可能有助于你的学习算法在放射科诊断中做的更好，算法学到了很多结构信息。图像形状信息，其中一些知识可能很有用，所以学会了图像识别，它就可能学到足够多的信息，可以了解不同图像的组成部分是怎样的，学到线条，点，曲线这些知识，也行对象的一小部分，这些知识有可能帮助你的放射科诊断网络，学习更快一些或者需要更少的学习数据

迁移学习，你可以不只加入一个新节点（如把输出节点替换掉），或者甚至往你的神经网络加入几个新层，这取决于你有多少数据，你可能只需重新训练网络的新层，也许你需要重新训练神经网络中更多的层

迁移学习起作用的场合是，迁移来源问题你有很多数据，但迁移目标问题没有那么多数据， 
如：图像识别有100W个样本，放射扫描图有100个样本，所以你从图像识别训练中学到的很多知识可以迁移并且真正帮你加强放射科识别任务的性能，即使你的放射科数据很少，

如： 你有10000小时训练过你的语音识别系统，所以这10000小时数据学到很多人类声音的特征，但触发字检测（新模型）也许只有1小时数据，所以这数据太小，不能用来拟合很多参数，所以这种情况，预先学到很多人类声音的特征，人类语言的组成部分等等知识，可以帮你建立一个很好的唤醒字检测器，即使你的数据集相对很小，

从数据量多的问题迁移到数据量少的问题，然后反过来的话，迁移学习可能就没有意义了


